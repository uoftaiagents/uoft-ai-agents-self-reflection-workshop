{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8458e22c",
   "metadata": {},
   "source": [
    "# 🔬 Advanced Experiments\n",
    "**UofT AI Agents Club - Advanced Track**\n",
    "\n",
    "Now that you've built a basic self-reflecting agent, let's push it further!\n",
    "\n",
    "## 🎯 What We'll Do\n",
    "1. **Smarter Agents** - More sophisticated reflection strategies\n",
    "2. **Domain Tests** - CS, ML, Systems problems\n",
    "3. **Performance** - Measure improvement quality\n",
    "4. **Your Turn** - Experiment with your own ideas\n",
    "\n",
    "**Prerequisites**: Complete [`workshop_tutorial.ipynb`](workshop_tutorial.ipynb) first\n",
    "\n",
    "Let's experiment! 🧪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df1cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Advanced Experiments Setup\n",
      "✅ All modules imported successfully!\n",
      "🧪 Ready for advanced experimentation!\n",
      "🔬 Advanced Self-Reflecting Agent ready!\n",
      "🎡 Multiple strategies and evaluation modes available!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Add the parent directory to sys.path so 'src' can be imported\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "print(\"🔬 Advanced Experiments Setup\")\n",
    "print(\"✅ All modules imported successfully!\")\n",
    "print(\"🧪 Ready for advanced experimentation!\")\n",
    "\n",
    "# Advanced Self-Reflecting Agent\n",
    "class AdvancedReflectiveAgent:\n",
    "    def __init__(self):\n",
    "        self.strategies = {\n",
    "            'technical': self._technical_generate,\n",
    "            'creative': self._creative_generate,\n",
    "            'systematic': self._systematic_generate\n",
    "        }\n",
    "        self.evaluation_modes = {\n",
    "            'critical': self._critical_evaluate,\n",
    "            'constructive': self._constructive_evaluate,\n",
    "            'comprehensive': self._comprehensive_evaluate\n",
    "        }\n",
    "    \n",
    "    def _technical_generate(self, problem):\n",
    "        \"\"\"Generate technical, detailed responses\"\"\"\n",
    "        if 'recursive' in problem.lower():\n",
    "            return \"For recursive optimization: 1) Add memoization to cache results, 2) Consider iterative alternatives, 3) Analyze time complexity O(n) vs O(2^n), 4) Use dynamic programming if overlapping subproblems exist.\"\n",
    "        elif 'algorithm' in problem.lower():\n",
    "            return \"Algorithm optimization approach: 1) Profile bottlenecks, 2) Choose optimal data structures, 3) Reduce algorithmic complexity, 4) Consider space-time tradeoffs.\"\n",
    "        elif 'system' in problem.lower():\n",
    "            return \"System design considerations: 1) Scalability patterns, 2) Database optimization, 3) Caching strategies, 4) Load balancing, 5) Monitoring and metrics.\"\n",
    "        return \"Technical analysis: Break down the problem, identify core constraints, design solution architecture, implement incrementally.\"\n",
    "    \n",
    "    def _creative_generate(self, problem):\n",
    "        \"\"\"Generate creative, out-of-the-box responses\"\"\"\n",
    "        return f\"Creative approach to '{problem}': Think beyond conventional solutions. What if we approached this from a completely different angle? Consider analogies from other domains, unconventional data structures, or novel algorithmic paradigms.\"\n",
    "    \n",
    "    def _systematic_generate(self, problem):\n",
    "        \"\"\"Generate systematic, methodical responses\"\"\"\n",
    "        return f\"Systematic solution for '{problem}': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics.\"\n",
    "    \n",
    "    def _critical_evaluate(self, response):\n",
    "        \"\"\"Critical evaluation - finds flaws and weaknesses\"\"\"\n",
    "        issues = []\n",
    "        if len(response) < 50:\n",
    "            issues.append(\"Response lacks sufficient detail and depth\")\n",
    "        if 'step' not in response.lower() and '1)' not in response:\n",
    "            issues.append(\"Missing clear step-by-step breakdown\")\n",
    "        if not any(word in response.lower() for word in ['complexity', 'performance', 'efficiency', 'optimize']):\n",
    "            issues.append(\"Lacks discussion of performance implications\")\n",
    "        return issues if issues else [\"Solid technical response\"]\n",
    "    \n",
    "    def _constructive_evaluate(self, response):\n",
    "        \"\"\"Constructive evaluation - suggests improvements\"\"\"\n",
    "        suggestions = []\n",
    "        if 'example' not in response.lower():\n",
    "            suggestions.append(\"Could benefit from concrete examples\")\n",
    "        if 'trade' not in response.lower():\n",
    "            suggestions.append(\"Should discuss trade-offs and alternatives\")\n",
    "        if len(response.split('.')) < 3:\n",
    "            suggestions.append(\"Could expand with more detailed explanation\")\n",
    "        return suggestions if suggestions else [\"Well-structured response\"]\n",
    "    \n",
    "    def _comprehensive_evaluate(self, response):\n",
    "        \"\"\"Comprehensive evaluation - checks multiple aspects\"\"\"\n",
    "        return self._critical_evaluate(response) + self._constructive_evaluate(response)\n",
    "    \n",
    "    def refine(self, response, critiques):\n",
    "        \"\"\"Refine response based on critiques\"\"\"\n",
    "        if not critiques or 'Solid' in str(critiques) or 'Well-structured' in str(critiques):\n",
    "            return response\n",
    "        \n",
    "        refined = response\n",
    "        \n",
    "        if 'lacks sufficient detail' in str(critiques):\n",
    "            refined += \" Additionally, consider implementation details, edge cases, and validation strategies.\"\n",
    "        \n",
    "        if 'step-by-step' in str(critiques):\n",
    "            refined = f\"Step-by-step approach: {refined}\"\n",
    "        \n",
    "        if 'performance implications' in str(critiques):\n",
    "            refined += \" Important: Analyze time and space complexity, benchmark performance, and optimize bottlenecks.\"\n",
    "        \n",
    "        if 'concrete examples' in str(critiques):\n",
    "            refined += \" For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²).\"\n",
    "        \n",
    "        if 'trade-offs' in str(critiques):\n",
    "            refined += \" Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\"\n",
    "        \n",
    "        return refined\n",
    "    \n",
    "    def solve(self, problem, generation_strategy='technical', evaluation_mode='critical', max_iterations=3):\n",
    "        \"\"\"Advanced solving with configurable strategies\"\"\"\n",
    "        print(f\"🔬 Problem: {problem}\")\n",
    "        print(f\"⚙️ Strategy: {generation_strategy} | Evaluation: {evaluation_mode}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Generate initial response\n",
    "        response = self.strategies[generation_strategy](problem)\n",
    "        \n",
    "        for i in range(max_iterations):\n",
    "            print(f\"\\n🔄 Iteration {i+1}\")\n",
    "            print(f\"💡 Response: {response}\")\n",
    "            \n",
    "            # Evaluate\n",
    "            critiques = self.evaluation_modes[evaluation_mode](response)\n",
    "            print(f\"🔍 Critique: {critiques[0] if critiques else 'No issues found'}\")\n",
    "            \n",
    "            # Check if we should stop\n",
    "            if not critiques or 'Solid' in str(critiques) or 'Well-structured' in str(critiques):\n",
    "                print(\"✅ Response satisfactory!\")\n",
    "                break\n",
    "            \n",
    "            # Refine\n",
    "            response = self.refine(response, critiques)\n",
    "            print(f\"✨ Refined: {response[:100]}...\" if len(response) > 100 else f\"✨ Refined: {response}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Simple metrics function\n",
    "def calculate_metrics(response):\n",
    "    \"\"\"Calculate basic metrics for the response\"\"\"\n",
    "    if not response:\n",
    "        return {\"length\": 0, \"words\": 0, \"sentences\": 0}\n",
    "    \n",
    "    return {\n",
    "        \"length\": len(response),\n",
    "        \"words\": len(response.split()),\n",
    "        \"sentences\": response.count('.') + response.count('!') + response.count('?'),\n",
    "        \"complexity_score\": len([w for w in response.split() if len(w) > 6]) / len(response.split()) if response.split() else 0\n",
    "    }\n",
    "\n",
    "# Create advanced agent\n",
    "advanced_agent = AdvancedReflectiveAgent()\n",
    "print(\"🔬 Advanced Self-Reflecting Agent ready!\")\n",
    "print(\"🎡 Multiple strategies and evaluation modes available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852942e5",
   "metadata": {},
   "source": [
    "## 🧪 Experiment 1: Technical Problem Solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013228db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Final Technical Result:\n",
      "For recursive optimization: 1) Add memoization to cache results, 2) Consider iterative alternatives, 3) Analyze time complexity O(n) vs O(2^n), 4) Use dynamic programming if overlapping subproblems exist.\n",
      "\n",
      "📊 Technical Strategy Metrics: {'length': 204, 'words': 28, 'sentences': 1, 'complexity_score': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>🔎 Show Full Reflection Trace</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> For recursive optimization: 1) Add memoization to cache results, 2) Consider iterative alternatives, 3) Analyze time complexity O(n) vs O(2^n), 4) Use dynamic programming if overlapping subproblems exist.<br><b>Critiques:</b><ul><li>Solid technical response</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧪 Experiment 1: Technical Problem Solving (Streamlined)\n",
    "from IPython.display import display, Markdown\n",
    "tech_problem = \"How can I optimize the performance of a recursive algorithm?\"\n",
    "\n",
    "# Run the agent and capture the trace\n",
    "trace = []\n",
    "def capture_trace(problem, strategy, evaluation, max_iterations):\n",
    "    responses = []\n",
    "    response = advanced_agent.strategies[strategy](problem)\n",
    "    for i in range(max_iterations):\n",
    "        critiques = advanced_agent.evaluation_modes[evaluation](response)\n",
    "        responses.append({\n",
    "            'iteration': i+1,\n",
    "            'response': response,\n",
    "            'critiques': critiques\n",
    "        })\n",
    "        if not critiques or 'Solid' in str(critiques) or 'Well-structured' in str(critiques):\n",
    "            break\n",
    "        response = advanced_agent.refine(response, critiques)\n",
    "    return responses, response\n",
    "\n",
    "trace, result1 = capture_trace(tech_problem, 'technical', 'critical', 2)\n",
    "\n",
    "# Show final result\n",
    "print(\"\\n🎯 Final Technical Result:\")\n",
    "print(result1)\n",
    "\n",
    "# Show metrics\n",
    "metrics = calculate_metrics(result1)\n",
    "print(f\"\\n📊 Technical Strategy Metrics: {metrics}\")\n",
    "\n",
    "# Show full trace in collapsible Markdown\n",
    "trace_md = \"\"\"<details><summary>🔎 Show Full Reflection Trace</summary>\\n\"\"\"\n",
    "for step in trace:\n",
    "    trace_md += f\"\\n<b>Iteration {step['iteration']}</b><br>\"\n",
    "    trace_md += f\"<b>Response:</b> {step['response']}<br>\"\n",
    "    if step['critiques']:\n",
    "        trace_md += \"<b>Critiques:</b><ul>\"\n",
    "        for c in step['critiques']:\n",
    "            trace_md += f\"<li>{c}</li>\"\n",
    "        trace_md += \"</ul>\"\n",
    "    trace_md += \"<hr>\"\n",
    "trace_md += \"</details>\"\n",
    "display(Markdown(trace_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497faaee",
   "metadata": {},
   "source": [
    "## 🌍 Experiment 2: Domain Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8801e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Domain Transfer Experiment:\n",
      "\n",
      "🔬 Algorithms Final Result:\n",
      "Systematic solution for 'What's the best sorting algorithm for large datasets?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "📊 Algorithms Metrics: {'length': 456, 'words': 67, 'sentences': 4, 'complexity_score': 0.417910447761194}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Algorithms)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Systematic solution for 'What's the best sorting algorithm for large datasets?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics.<br><b>Critiques:</b><ul><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li><li>Could expand with more detailed explanation</li></ul><hr>\n",
       "<b>Iteration 2</b><br><b>Response:</b> Systematic solution for 'What's the best sorting algorithm for large datasets?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.<br><b>Critiques:</b><ul><li>Well-structured response</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Systems Final Result:\n",
      "Systematic solution for 'How do I handle race conditions in concurrent programming?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "📊 Systems Metrics: {'length': 461, 'words': 68, 'sentences': 4, 'complexity_score': 0.39705882352941174}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Systems)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Systematic solution for 'How do I handle race conditions in concurrent programming?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics.<br><b>Critiques:</b><ul><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li><li>Could expand with more detailed explanation</li></ul><hr>\n",
       "<b>Iteration 2</b><br><b>Response:</b> Systematic solution for 'How do I handle race conditions in concurrent programming?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.<br><b>Critiques:</b><ul><li>Well-structured response</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Machine Learning Final Result:\n",
      "Systematic solution for 'How do I prevent overfitting in my neural network?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "📊 Machine Learning Metrics: {'length': 453, 'words': 68, 'sentences': 4, 'complexity_score': 0.39705882352941174}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Machine Learning)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Systematic solution for 'How do I prevent overfitting in my neural network?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics.<br><b>Critiques:</b><ul><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li><li>Could expand with more detailed explanation</li></ul><hr>\n",
       "<b>Iteration 2</b><br><b>Response:</b> Systematic solution for 'How do I prevent overfitting in my neural network?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.<br><b>Critiques:</b><ul><li>Well-structured response</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Software Engineering Final Result:\n",
      "Systematic solution for 'What design patterns improve code maintainability?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "📊 Software Engineering Metrics: {'length': 453, 'words': 65, 'sentences': 4, 'complexity_score': 0.4153846153846154}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Software Engineering)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Systematic solution for 'What design patterns improve code maintainability?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics.<br><b>Critiques:</b><ul><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li><li>Could expand with more detailed explanation</li></ul><hr>\n",
       "<b>Iteration 2</b><br><b>Response:</b> Systematic solution for 'What design patterns improve code maintainability?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.<br><b>Critiques:</b><ul><li>Well-structured response</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Domain Performance Summary:\n",
      "• Algorithms: 456 chars\n",
      "• Systems: 461 chars\n",
      "• Machine Learning: 453 chars\n",
      "• Software Engineering: 453 chars\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Experiment 2: Domain Transfer (Streamlined)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "domains = {\n",
    "    \"Algorithms\": \"What's the best sorting algorithm for large datasets?\",\n",
    "    \"Systems\": \"How do I handle race conditions in concurrent programming?\", \n",
    "    \"Machine Learning\": \"How do I prevent overfitting in my neural network?\",\n",
    "    \"Software Engineering\": \"What design patterns improve code maintainability?\"\n",
    "}\n",
    "\n",
    "print(\"🌍 Domain Transfer Experiment:\")\n",
    "\n",
    "results = {}\n",
    "traces = {}\n",
    "for domain, problem in domains.items():\n",
    "    trace = []\n",
    "    def capture_trace(problem, strategy, evaluation, max_iterations):\n",
    "        responses = []\n",
    "        response = advanced_agent.strategies[strategy](problem)\n",
    "        for i in range(max_iterations):\n",
    "            critiques = advanced_agent.evaluation_modes[evaluation](response)\n",
    "            responses.append({\n",
    "                'iteration': i+1,\n",
    "                'response': response,\n",
    "                'critiques': critiques\n",
    "            })\n",
    "            if not critiques or 'Solid' in str(critiques) or 'Well-structured' in str(critiques):\n",
    "                break\n",
    "            response = advanced_agent.refine(response, critiques)\n",
    "        return responses, response\n",
    "    trace, result = capture_trace(problem, 'systematic', 'constructive', 2)\n",
    "    results[domain] = len(result)\n",
    "    traces[domain] = trace\n",
    "    print(f\"\\n🔬 {domain} Final Result:\")\n",
    "    print(result)\n",
    "    metrics = calculate_metrics(result)\n",
    "    print(f\"📊 {domain} Metrics: {metrics}\")\n",
    "    # Show full trace in collapsible Markdown\n",
    "    trace_md = f\"<details><summary>Show Full Trace ({domain})</summary>\\n\"\n",
    "    for step in trace:\n",
    "        trace_md += f\"\\n<b>Iteration {step['iteration']}</b><br>\"\n",
    "        trace_md += f\"<b>Response:</b> {step['response']}<br>\"\n",
    "        if step['critiques']:\n",
    "            trace_md += \"<b>Critiques:</b><ul>\"\n",
    "            for c in step['critiques']:\n",
    "                trace_md += f\"<li>{c}</li>\"\n",
    "            trace_md += \"</ul>\"\n",
    "        trace_md += \"<hr>\"\n",
    "    trace_md += \"</details>\"\n",
    "    display(Markdown(trace_md))\n",
    "\n",
    "print(\"\\n📈 Domain Performance Summary:\")\n",
    "for domain, length in results.items():\n",
    "    print(f\"• {domain}: {length} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac91d4",
   "metadata": {},
   "source": [
    "## ⚔️ Experiment 3: Strategy Showdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e10706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚔️ Strategy Comparison:\n",
      "\n",
      "🛠️ Technical Final Result:\n",
      "System design considerations: 1) Scalability patterns, 2) Database optimization, 3) Caching strategies, 4) Load balancing, 5) Monitoring and metrics. Important: Analyze time and space complexity, benchmark performance, and optimize bottlenecks. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "→ technical: 456 characters\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Technical)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> System design considerations: 1) Scalability patterns, 2) Database optimization, 3) Caching strategies, 4) Load balancing, 5) Monitoring and metrics.<br><b>Critiques:</b><ul><li>Lacks discussion of performance implications</li><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li><li>Could expand with more detailed explanation</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛠️ Creative Final Result:\n",
      "Step-by-step approach: Creative approach to 'How do I debug a complex software system?': Think beyond conventional solutions. What if we approached this from a completely different angle? Consider analogies from other domains, unconventional data structures, or novel algorithmic paradigms. Important: Analyze time and space complexity, benchmark performance, and optimize bottlenecks. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "→ creative: 597 characters\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Creative)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Creative approach to 'How do I debug a complex software system?': Think beyond conventional solutions. What if we approached this from a completely different angle? Consider analogies from other domains, unconventional data structures, or novel algorithmic paradigms.<br><b>Critiques:</b><ul><li>Missing clear step-by-step breakdown</li><li>Lacks discussion of performance implications</li><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛠️ Systematic Final Result:\n",
      "Systematic solution for 'How do I debug a complex software system?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics. Important: Analyze time and space complexity, benchmark performance, and optimize bottlenecks. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "→ systematic: 539 characters\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>Show Full Trace (Systematic)</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Systematic solution for 'How do I debug a complex software system?': 1) Problem analysis and requirements, 2) Research existing solutions, 3) Design multiple approaches, 4) Prototype and test, 5) Iterate and refine based on metrics.<br><b>Critiques:</b><ul><li>Lacks discussion of performance implications</li><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li><li>Could expand with more detailed explanation</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Strategy Performance:\n",
      "🥇 creative: 597 chars\n",
      "🥈 systematic: 539 chars\n",
      "🥉 technical: 456 chars\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Experiment 3: Strategy Showdown (Streamlined)\n",
    "from IPython.display import display, Markdown\n",
    "test_problem = \"How do I debug a complex software system?\"\n",
    "strategies = ['technical', 'creative', 'systematic']\n",
    "\n",
    "print(\"⚔️ Strategy Comparison:\")\n",
    "\n",
    "performance = {}\n",
    "traces = {}\n",
    "for strategy in strategies:\n",
    "    trace = []\n",
    "    def capture_trace(problem, strategy, evaluation, max_iterations):\n",
    "        responses = []\n",
    "        response = advanced_agent.strategies[strategy](problem)\n",
    "        for i in range(max_iterations):\n",
    "            critiques = advanced_agent.evaluation_modes['comprehensive'](response)\n",
    "            responses.append({\n",
    "                'iteration': i+1,\n",
    "                'response': response,\n",
    "                'critiques': critiques\n",
    "            })\n",
    "            if not critiques or 'Solid' in str(critiques) or 'Well-structured' in str(critiques):\n",
    "                break\n",
    "            response = advanced_agent.refine(response, critiques)\n",
    "        return responses, response\n",
    "    trace, result = capture_trace(test_problem, strategy, 'comprehensive', 1)\n",
    "    performance[strategy] = len(result)\n",
    "    traces[strategy] = trace\n",
    "    print(f\"\\n🛠️ {strategy.title()} Final Result:\")\n",
    "    print(result)\n",
    "    print(f\"→ {strategy}: {len(result)} characters\")\n",
    "    # Show full trace in collapsible Markdown\n",
    "    trace_md = f\"<details><summary>Show Full Trace ({strategy.title()})</summary>\\n\"\n",
    "    for step in trace:\n",
    "        trace_md += f\"\\n<b>Iteration {step['iteration']}</b><br>\"\n",
    "        trace_md += f\"<b>Response:</b> {step['response']}<br>\"\n",
    "        if step['critiques']:\n",
    "            trace_md += \"<b>Critiques:</b><ul>\"\n",
    "            for c in step['critiques']:\n",
    "                trace_md += f\"<li>{c}</li>\"\n",
    "            trace_md += \"</ul>\"\n",
    "        trace_md += \"<hr>\"\n",
    "    trace_md += \"</details>\"\n",
    "    display(Markdown(trace_md))\n",
    "\n",
    "print(\"\\n🏆 Strategy Performance:\")\n",
    "sorted_results = sorted(performance.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (strategy, score) in enumerate(sorted_results, 1):\n",
    "    medal = \"🥇\" if i == 1 else \"🥈\" if i == 2 else \"🥉\"\n",
    "    print(f\"{medal} {strategy}: {score} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef27fc2",
   "metadata": {},
   "source": [
    "## 🎯 Your Turn: Custom Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f96d24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Your Custom Experiment:\n",
      "Problem: How do I learn machine learning effectively?\n",
      "Strategy: creative | Evaluation: constructive\n",
      "\n",
      "🎯 Final Result:\n",
      "Creative approach to 'How do I learn machine learning effectively?': Think beyond conventional solutions. What if we approached this from a completely different angle? Consider analogies from other domains, unconventional data structures, or novel algorithmic paradigms. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.\n",
      "\n",
      "📊 Your Result Analysis:\n",
      "• Length: 482 characters\n",
      "• Words: 68 words\n",
      "• Strategy used: creative\n",
      "• Evaluation mode: constructive\n",
      "• Complexity score: 0.41\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>🔎 Show Full Reflection Trace</summary>\n",
       "\n",
       "<b>Iteration 1</b><br><b>Response:</b> Creative approach to 'How do I learn machine learning effectively?': Think beyond conventional solutions. What if we approached this from a completely different angle? Consider analogies from other domains, unconventional data structures, or novel algorithmic paradigms.<br><b>Critiques:</b><ul><li>Could benefit from concrete examples</li><li>Should discuss trade-offs and alternatives</li></ul><hr>\n",
       "<b>Iteration 2</b><br><b>Response:</b> Creative approach to 'How do I learn machine learning effectively?': Think beyond conventional solutions. What if we approached this from a completely different angle? Consider analogies from other domains, unconventional data structures, or novel algorithmic paradigms. For example, in a sorting algorithm, this could mean choosing quicksort O(n log n) over bubble sort O(n²). Key trade-offs include memory vs speed, simplicity vs performance, and development time vs optimization.<br><b>Critiques:</b><ul><li>Well-structured response</li></ul><hr></details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Try These Modifications:\n",
      "1. Change the custom_problem to something you're curious about\n",
      "2. Try different strategy combinations\n",
      "3. Adjust custom_iterations (1-5)\n",
      "4. Compare results with different evaluation modes\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Your Turn: Custom Experiment (Streamlined)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Edit these variables to try your own experiment!\n",
    "custom_problem = \"How do I learn machine learning effectively?\"  # Change this!\n",
    "custom_strategy = 'creative'  # Try: 'technical', 'creative', 'systematic'\n",
    "custom_evaluation = 'constructive'  # Try: 'critical', 'constructive', 'comprehensive'\n",
    "custom_iterations = 3  # Adjust 1-5\n",
    "\n",
    "print(\"🎯 Your Custom Experiment:\")\n",
    "print(f\"Problem: {custom_problem}\")\n",
    "print(f\"Strategy: {custom_strategy} | Evaluation: {custom_evaluation}\")\n",
    "\n",
    "# Run the agent and capture the trace\n",
    "trace = []\n",
    "def capture_trace(problem, strategy, evaluation, max_iterations):\n",
    "    responses = []\n",
    "    response = advanced_agent.strategies[strategy](problem)\n",
    "    for i in range(max_iterations):\n",
    "        critiques = advanced_agent.evaluation_modes[evaluation](response)\n",
    "        responses.append({\n",
    "            'iteration': i+1,\n",
    "            'response': response,\n",
    "            'critiques': critiques\n",
    "        })\n",
    "        if not critiques or 'Solid' in str(critiques) or 'Well-structured' in str(critiques):\n",
    "            break\n",
    "        response = advanced_agent.refine(response, critiques)\n",
    "    return responses, response\n",
    "\n",
    "trace, custom_result = capture_trace(custom_problem, custom_strategy, custom_evaluation, custom_iterations)\n",
    "\n",
    "# Show final result\n",
    "print(\"\\n🎯 Final Result:\")\n",
    "print(custom_result)\n",
    "\n",
    "# Show metrics\n",
    "custom_metrics = calculate_metrics(custom_result)\n",
    "print(f\"\\n📊 Your Result Analysis:\")\n",
    "print(f\"• Length: {len(custom_result)} characters\")\n",
    "print(f\"• Words: {len(custom_result.split())} words\")\n",
    "print(f\"• Strategy used: {custom_strategy}\")\n",
    "print(f\"• Evaluation mode: {custom_evaluation}\")\n",
    "print(f\"• Complexity score: {custom_metrics['complexity_score']:.2f}\")\n",
    "\n",
    "# Show full trace in collapsible Markdown\n",
    "trace_md = \"\"\"<details><summary>🔎 Show Full Reflection Trace</summary>\\n\"\"\"\n",
    "for step in trace:\n",
    "    trace_md += f\"\\n<b>Iteration {step['iteration']}</b><br>\"\n",
    "    trace_md += f\"<b>Response:</b> {step['response']}<br>\"\n",
    "    if step['critiques']:\n",
    "        trace_md += \"<b>Critiques:</b><ul>\"\n",
    "        for c in step['critiques']:\n",
    "            trace_md += f\"<li>{c}</li>\"\n",
    "        trace_md += \"</ul>\"\n",
    "    trace_md += \"<hr>\"\n",
    "trace_md += \"</details>\"\n",
    "display(Markdown(trace_md))\n",
    "\n",
    "print(\"\\n✨ Try These Modifications:\")\n",
    "print(\"1. Change the custom_problem to something you're curious about\")\n",
    "print(\"2. Try different strategy combinations\")\n",
    "print(\"3. Adjust custom_iterations (1-5)\")\n",
    "print(\"4. Compare results with different evaluation modes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd3f3a",
   "metadata": {},
   "source": [
    "## 🎉 Experiment Results & Next Steps\n",
    "\n",
    "Congratulations! You've completed advanced experiments with self-reflecting AI agents! 🧠✨\n",
    "\n",
    "### 📊 What You've Discovered:\n",
    "- How agents handle different problem domains\n",
    "- The impact of different strategies on response quality\n",
    "- Performance differences across problem types\n",
    "- The agent's step-by-step improvement process\n",
    "\n",
    "### 🚀 What's Next?\n",
    "\n",
    "1. **Deep Dive**: Explore [`research_extensions.ipynb`](research_extensions.ipynb)\n",
    "   - Meta-reflection (agents critiquing their own critique process)\n",
    "   - Multi-agent collaboration\n",
    "   - Advanced research techniques\n",
    "\n",
    "2. **Build Your Own**: Create specialized agents\n",
    "   - Code review assistants\n",
    "   - Writing improvement tools\n",
    "   - Domain-specific problem solvers\n",
    "\n",
    "3. **Join the Club**: Continue learning with UofT AI Agents Club\n",
    "   - Weekly workshops\n",
    "   - Research projects\n",
    "   - Industry connections\n",
    "\n",
    "### 🔍 Key Insights from Your Experiments:\n",
    "- **Strategy Selection**: Different problems benefit from different approaches\n",
    "- **Evaluation Modes**: Critical vs constructive evaluation serves different purposes\n",
    "- **Domain Adaptation**: Agents can adapt to various CS fields\n",
    "- **Self-Improvement**: Agents genuinely improve their reasoning through reflection\n",
    "\n",
    "**Keep experimenting and pushing the boundaries! 🌟**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb53050-4cac-4222-8119-2b4fb656be4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
